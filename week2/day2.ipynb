{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (4.3.5)\n",
      "Collecting jupyterlab\n",
      "  Downloading jupyterlab-4.3.6-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (0.28.1)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (6.29.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (24.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (65.5.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (6.4.2)\n",
      "Requirement already satisfied: traitlets in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (4.8.0)\n",
      "Requirement already satisfied: certifi in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (9.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab) (26.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab) (2.1.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-core->jupyterlab) (308)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (2.0.15)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from anyio->httpx>=0.25.0->jupyterlab) (4.12.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: colorama in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (2.8.2)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.3.0)\n",
      "Requirement already satisfied: webencodings in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: fqdn in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
      "Requirement already satisfied: wcwidth in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: pycparser in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in d:\\codes\\hackathon\\llm_engineering\\llms\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
      "Downloading jupyterlab-4.3.6-py3-none-any.whl (11.7 MB)\n",
      "   ---------------------------------------- 0.0/11.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.7 MB 2.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.4/11.7 MB 4.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.5/11.7 MB 6.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.9/11.7 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.7 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.7/11.7 MB 8.5 MB/s eta 0:00:00\n",
      "Installing collected packages: jupyterlab\n",
      "  Attempting uninstall: jupyterlab\n",
      "    Found existing installation: jupyterlab 4.3.5\n",
      "    Uninstalling jupyterlab-4.3.5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'd:\\\\codes\\\\hackathon\\\\llm_engineering\\\\llms\\\\scripts\\\\jupyter-lab.exe'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "import gradio as gr\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\"\n",
    "MODEL=\"llama3.2:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_llama(propmpt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": propmpt}\n",
    "    ]\n",
    "    completion = ollama.chat(model=MODEL, messages=messages)\n",
    "    return completion.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help you, but I'm a large language model, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the current weather:\\n\\n1. **Check online weather websites**: You can check websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for up-to-date weather forecasts.\\n2. **Use a mobile app**: Download a weather app on your smartphone, such as Dark Sky or Weather Underground, to get current weather conditions and forecasts.\\n3. **Tune into local news**: Watch local news or listen to local radio stations to get the latest weather forecast.\\n\\nPlease note that I can provide general information about different types of weather or help with other topics if you'd like!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_llama(\"What is today's weather?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a simple function\n",
    "def shout(text):\n",
    "    print(f\"Shout has been called with input: {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input: hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shout(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs and Outputs\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Response:\", lines=6)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a helpful assistant that responds in markdown\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_llama,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\",\n",
    "    title=\"Llama Chat\",\n",
    "    description=\"A simple chatbot that responds in markdown.\"\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a call that streams back results\n",
    "\n",
    "def stream_llama(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    completion = ollama.chat(model=MODEL, messages=messages, stream=True)\n",
    "    result = \"\"\n",
    "    for message in completion:\n",
    "        result += message.message.content\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_llama,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\",\n",
    "    title=\"Llama Chat\",\n",
    "    description=\"A simple chatbot that responds in markdown.\"\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model == \"llama3.2:latest\":\n",
    "        result = stream_llama(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6), gr.Dropdown([\"llama3.2:latest\"], label=\"Model:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\",\n",
    "    title=\"Llama Chat\",\n",
    "    js = force_dark_mode,\n",
    "    description=\"A simple chatbot that responds in markdown.\"\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that analyzes the contents of a company website landing page \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model):\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += Website(url).get_contents()\n",
    "    if model==\"llama3.2:latest\":\n",
    "        result = stream_llama(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object stream_brochure at 0x000001961162D030>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_brochure(\"ED\", \"https://edwarddonner.com\", \"llama3.2:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"llama3.2:latest\"], label=\"Select model\")],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
