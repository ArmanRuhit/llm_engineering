{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Project - Airline AI Assistant",
   "id": "206f164066f171af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import ollama\n",
    "import gradio as gr\n"
   ],
   "id": "d335d28ab728dfc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "MODEL = \"llama3.2:latest\"",
   "id": "3d7d2519cd8a9b5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI.\"\n",
    "system_message += \" Give short, courteous answers, no more than 1 sentence.\"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ],
   "id": "f383d26fa330a24a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response.message.content"
   ],
   "id": "3d0c6ba0ff7fe915",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gr.ChatInterface(fn=chat, type=\"messages\").launch()",
   "id": "a2c522752371b5c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tools\n",
    "\n",
    "Tools are an incredibly powerful feature provided by the frontier LLMs.\n",
    "\n",
    "With tools, you can write a function, and have the LLM call that function as part of its response.\n",
    "\n",
    "Sounds almost spooky.. we're giving it the power to run code on our machine?\n",
    "\n"
   ],
   "id": "b34b18fea35294da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# let's start by making a useful function\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city =  destination_city.lower()\n",
    "    print(ticket_prices.get(city, \"Unknown\"))\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ],
   "id": "d36228bd62cbda39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# There's a particular dictionary structure that's required to describe out function\n",
    "\n",
    "price_function = {\n",
    "    \"name\" : \"get_ticket_price\",\n",
    "    \"description\" : \"Get the price of a return ticket to the destination city. Call this whatever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city \",\n",
    "    \"parameters\" :{\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that hte customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ],
   "id": "4b774983dc2a6d32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# And this is included in a list of tools\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": price_function}\n",
    "]"
   ],
   "id": "f4b9715f70836674",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Getting OpenAI to use our Tool\n",
    "\n",
    "The tool is included in the `tools` list, which is passed to the `ollama.chat` function as an argument.\n",
    "\n",
    "The LLM will now be able to call our function whenever it needs to know the price of a ticket to a particular city.\n",
    "\n"
   ],
   "id": "31f53cd52bdfe820"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def chat(message, history):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message}\n",
    "    ] + history + [\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat(model=MODEL, messages=messages, tools=tools)\n",
    "    print(response)\n",
    "    if response.get(\"done_reason\") == \"stop\":\n",
    "        tool_call_message = response[\"message\"]\n",
    "        tool_response, city = handle_tool_call(tool_call_message)\n",
    "        messages.append(tool_call_message)\n",
    "        messages.append(tool_response)\n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response.message.content"
   ],
   "id": "5c3b82f4588f928e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## We have to write that function handle_tool_call\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = tool_call.function.arguments\n",
    "    city = arguments.get(\"destination_city\")\n",
    "    price = get_ticket_price(city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city, \"price\": price}),\n",
    "    }\n",
    "    return response, city"
   ],
   "id": "11bbb8b74948d1c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# chat(\"How much is a ticket to Berlin\", [])",
   "id": "2bc5f73ac578deee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gr.ChatInterface(fn=chat, type=\"messages\").launch()",
   "id": "d646ef97961ddc01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a41c97ca03e06190",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
